# -*- coding: utf-8 -*-
"""financialQA.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1vi-LNZmeJCtDdhrl2PEXa1-H3wQRwg27
"""

# Install necessary libraries
# !pip install transformers datasets accelerate bitsandbytes peft openai

# Import necessary libraries
import os

import torch
from datasets import load_dataset
from peft import LoraConfig, TaskType, get_peft_model
from transformers import (AutoModelForCausalLM, AutoTokenizer, Trainer,
                          TrainingArguments)

"""## GPT 3.5 turbo"""

import json

import openai
from datasets import load_dataset

# Load the dataset
dataset = load_dataset("PatronusAI/financebench")

# Set your OpenAI API key
# openai.api_key = "your-openai-api-key"

# Prepare the dataset in the required format
train_data = []
for example in dataset['train']:
    # Combine the prompt and answer in the chat format
    messages = [
        {"role": "system", "content": "You are a helpful assistant specialized in financial analysis."},
        {"role": "user", "content": f"Question: {example['question']}\nEvidence: {example['evidence_text']}"},
        {"role": "assistant", "content": example['answer']}
    ]
    train_data.append({"messages": messages})

# Save the prepared dataset to a JSONL file
with open('fine_tune_train_chat.jsonl', 'w') as f:
    for item in train_data:
        f.write(json.dumps(item) + "\n")

# # Prepare the data
# !openai tools fine_tunes.prepare_data -f fine_tune_train_chat.jsonl

import os

# Set your OpenAI API key
os.environ['OPENAI_API_KEY'] = 'Your OpenAI key'

# Upload the dataset
# !openai api files.create -f fine_tune_train_chat.jsonl -p fine-tune

# # Fine-tune the model
# !openai api fine_tunes.create -t fine_tune_train_prepared.jsonl -m gpt-3.5-turbo
from openai import OpenAI

# client = OpenAI(api_key="your openai api key")

client.fine_tuning.jobs.create(
  training_file="your file id",
  model="gpt-3.5-turbo",
  hyperparameters={
        "batch_size": 8,
        "learning_rate_multiplier": 1.5,
        "n_epochs": 1
    }
)

"""##Monitoring the Fine-Tuning Job
You can monitor the status of your fine-tuning job using the OpenAI API. Hereâ€™s how you can periodically check the status:
"""

client.fine_tuning.jobs.retrieve("your job id")


import time


def check_fine_tuning_status(job_id):
    response = client.fine_tuning.jobs.retrieve(job_id)
    status = response.status
    return status

job_id = 'ftjob-7IksTJgHsH6fCrpLdHAY05hX'  # Replace with your fine-tuning job ID

while True:
    status = check_fine_tuning_status(job_id)
    print(f"Fine-tuning job status: {status}")
    if status in ['succeeded', 'failed']:
        break
    time.sleep(60)  # Wait for 1 minute before checking the status again



"""## llama3"""

import os

import torch
from datasets import load_dataset
from peft import LoraConfig, get_peft_model
from torch.utils.data import Dataset
from transformers import (AutoModelForCausalLM, AutoTokenizer, Trainer,
                          TrainingArguments)

# Load the dataset
dataset = load_dataset("PatronusAI/financebench")

# Prepare the dataset
train_data = []
for example in dataset['train']:
    combined_prompt = f"Question: {example['question']}\nEvidence: {example['evidence_text']}\nAnswer:"
    train_data.append({
        "prompt": combined_prompt,
        "completion": example['answer']
    })

# Save the prepared dataset to a JSONL file
import json

with open('fine_tune_train.jsonl', 'w') as f:
    for item in train_data:
        f.write(json.dumps(item) + "\n")

# Load tokenizer and model
model_name = "meta-llama/Meta-Llama-3-8B-Instruct"
# model_name = "meta-llama/Llama-2-7b-chat-hf"
# Set your Hugging Face token as an environment variable
os.environ["HF_TOKEN"] = "your huggingface token"
# Set your Hugging Face token
hf_token = "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"
tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=hf_token)
# Add padding token to the tokenizer
tokenizer.pad_token = tokenizer.eos_token
# Load model with 8-bit quantization
model = AutoModelForCausalLM.from_pretrained(model_name, load_in_8bit=True, use_auth_token=hf_token, device_map="auto")

# Define LoRa configuration
lora_config = LoraConfig(
    r=16,
    lora_alpha=32,
    target_modules=["q_proj", "v_proj"],
    lora_dropout=0.1,
    bias="none"
)
model = get_peft_model(model, lora_config)

# Define the dataset class
class FinanceBenchDataset(Dataset):
    def __init__(self, data, tokenizer):
        self.data = data
        self.tokenizer = tokenizer

    def __len__(self):
        return len(self.data)

    def __getitem__(self, idx):
        item = self.data[idx]
        prompt = item['prompt']
        completion = item['completion']
        inputs = self.tokenizer(prompt, return_tensors="pt", truncation=True, padding="max_length", max_length=512)
        labels = self.tokenizer(completion, return_tensors="pt", truncation=True, padding="max_length", max_length=512).input_ids
        inputs['labels'] = labels
        return {key: val.squeeze() for key, val in inputs.items()}

train_dataset = FinanceBenchDataset(train_data, tokenizer)

# Define training arguments and trainer
training_args = TrainingArguments(
    output_dir="./results",
    per_device_train_batch_size=1,  # Reduced batch size
    gradient_accumulation_steps=4,  # Gradient accumulation
    num_train_epochs=3,
    logging_dir="./logs",
    logging_steps=10,
    save_steps=100,
    # evaluation_strategy="steps",
    # eval_steps=100,
    save_total_limit=2,
    learning_rate=5e-5,
    weight_decay=0.01,
    fp16=True,
    push_to_hub=False
)

trainer = Trainer(
    model=model,
    args=training_args,
    train_dataset=train_dataset,
    tokenizer=tokenizer
)

# Train the model
trainer.train()

# Save the fine-tuned model
model.save_pretrained("finetuned_llama3_model")
tokenizer.save_pretrained("finetuned_llama3_model")

